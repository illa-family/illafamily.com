---
title: Hugging Face API
metaTitle: Hugging Face API に接続
desc: ILLA での Hugging Face API の使い方を学ぶ
tagCategory: doc_menu_hugging_face_api_click
crowdinRepo: https://crowdin.com/multilingual/illacloud-website/213?languages=ja&filter=basic&value=0
categoryName: 🔨 統合
categoryPriority: 3
postPriority: 1
---

## <h2 hidden>Hugging Face API</h2>

Hugging Faceは機械学習コミュニティのGithubであり、現在数十万の事前訓練されたモデルと10,000のデータセットが利用可能です。 他の業界の専門家が共有するモデルやデータセットに自由にアクセスしたり、Hugging Faceにモデルをホストしてデプロイしたりできます。

Hugging Faceライブラリで利用可能なモデルのいくつかの例は次のとおりです。

1.  BERT(双方向エンコーダ表現のトランスフォーマー):BERTはGoogleがさまざまなNLPタスクのために開発したトランスベースのモデルです。 言語理解と機械翻訳タスクにおいて、最先端の成果を達成しています。
2.  GPT(Generative Pre-training Transformer):GPTは、OpenAIによって開発された別のトランスベースのモデルです。 これは、主に翻訳やテキスト要約などの言語生成タスクに使用されます。
3.  RoBERTa(ロバスト最適化されたBERT):RoBERTaは、さまざまなNLPタスクでBERTのパフォーマンスを向上させるために開発されたBERTモデルの拡張機能です。
4.  XLNet (eXtraordinary LanguageNet): XLNetは、言語理解タスクにおけるトランスモデルのパフォーマンスを向上させるために、Googleが開発したトランスベースのモデルです。
5.  ALBERT(Lite BERT):ALBERTはNLPタスクで良好なパフォーマンスを維持しながら、より効率的でより速く訓練するように開発されたBERTモデルのバージョンです。

### ILLAビルダーでHugging Faceでできること

Hugging Faceでは、13万以上の機械学習モデルがパブリックAPIを通じて利用可能で、<https://huggingface.co/models>で無料でテストできます。 さらに、本番シナリオのソリューションが必要な場合は、[https://hugggingface.co/docs/conference-endpoints/index](https://huggingface.co/docs/conference-endpoints/index)でデプロイおよびアクセスできるHugging Faceの推論エンドポイントを使用できます。

ILLA Builderには、数十の一般的なフロントエンドコンポーネントが用意されており、特定のニーズに基づいてさまざまなフロントエンドインターフェイスを迅速に構築できます。 同時に、ILLAはHugging Faceへの接続を提供し、APIに素早く接続し、リクエストを送信し、返されたデータを受け取ることができます。 APIとフロントエンドコンポーネントを接続することで ユーザーがフロントエンドからコンテンツを入力してAPIに送信できるという要件を実装できます。 APIは、フロントエンドに表示される生成されたコンテンツを返します。

### Hugging Face API リソースを設定します

| プロパティー | 必須 | 説明                                                                    |
| ------ | -- | --------------------------------------------------------------------- |
| 名前     | 必須 | ILLA で表示するリソース名を定義します。                                                |
| トークン   | 必須 | ユーザーアクセスまたは API トークン。 https://huggingface.co/settings/tokensで入手できます。  |

### アクションの設定

| プロパティー   | 必須 | 説明                                                                                                                           |
| -------- | -- | ---------------------------------------------------------------------------------------------------------------------------- |
| モデル ID   | 必須 | モデルを検索: https://huggingface.co/models                                                                                        |
| パラメータの種類 | 必須 | エンドポイントのパラメータタイプ。 たとえば、エンドポイントにテキスト入力が必要な場合は、「inputs」パラメータにテキストを入力します。 エンドポイントにJSON入力が必要な場合は、「inputs」パラメータをJSONまたはキー値で入力します。 |
| パラメータ    | 必須 | パラメータを入力します。 コンポーネントのデータを使用するには {{ componentName.value }} を使用します。                                                            |

# ILLA Builder で Hugging Face を使用する方法

## Usecase 1

### ステップ1: ILLA Builder上でコンポーネントを使用してUIを構築する

ここでは、テキスト応答を出力するためのテキストプロンプトとテキスト質問を入力する単純なテキストを構築する方法を紹介します。 

「元のテキストを入力」と「ここに質問を入力」とラベル付けされた2つのテキストエリアコンポーネントが必要です ボタンコンポーネントには「実行」というラベルが付けられ、テキストの出力テキストには「元」というラベルの付いたテキストエリアコンポーネントがあります。 以下の画像は、上記のような例です。

![hfapi](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi1.png)

### ステップ 2: Hugging Face Resourceを作成し、アクションを設定します

アクションリストで [+ 新規] をクリックし、[Hugging Face Inference API] を選択します。

![hfapi2](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi2.png)

Hugging Faceに接続するには、フォームに入力してください:

名前: ILLA に表示される名前

トークン: Hugging Faceformat@@0(https://hugggingface.co/settings/tokens)

![hfapi3](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi3.png)

アクションを設定する前に、Hugging Faceでモデル情報を確認します。

[Hugging Face Model Page](https://huggingface.co/models) でモデルを選択してください

例として[deepset/roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2)を使用しましょう。 詳細ページを入力>デプロイ>推論APIをクリックします。

![hfapi4](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi4.png)

`inputs`の後のパラメータはILLAで入力すべきものです。 

![hfapi5](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi5.png)

ILLAビルダーでは、Model IDとParameterを入力します。 上記のモデルを例に挙げると、`inputs`はキーと値のペアであるため、キーと値またはJSONで入力できます。 

![hfapi6](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi6.png)

![hfapi7](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi7.png)

また、Hugging Face Inference API 接続を満たすことができるテキスト入力とバイナリ入力もサポートします。

### ステップ 3: アクションをコンポーネントに接続

ユーザーのフロントエンド入力を API に渡すには、{{ を使用してコンポーネントに入力されたデータを取得できます。 例えば、input2 は質問を入力するためのコンポーネントであり、input1 は入力コンテキストへのコンポーネントです。 キーに `question` と `context` を入力し、値に `{{ input.value }}` を入力します。

```jsx
{
"question": {{input2.value}},
"context": {{input1.value}}
}
```

Actionの出力データをフロントエンドコンポーネントに表示する前に、異なるモデルの出力がどのフィールドに配置されているかを確認する必要があります。 まだ `deepset/roberta-base-squad2` を例にとってみると、結果は以下のとおりです。

![hfapi8](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi8.png)

そして、`{{ textQuestion.data[0].answer }}`（`textQuestion`はアクションの名前です）で答えを得ることができます。 

![hfapi9](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi9.png)

### デモ

![hfapi10](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi10.gif)

![hfapi11](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi11.gif)

## Usecase 2

ここでは、Illa Cloudで安定拡散モデルthorughのHugging Face APIを使用する方法を説明します。

**ステップ 1: フロントエンドインターフェースの構築**

入力フィールド、ボタン、画像などの必須コンポーネントを配置するために、ドラッグアンドドロップ手法を利用してフロントエンドインターフェースを構築します。 コンポーネントのスタイルを調整した後、以下の完全なウェブページを取得します。

![hugging_layout](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_layout.png)

**ステップ 2: リソースとアクションを作成**

Hugging Face Inference API を利用してStable Diffusion modelに接続するリソースとアクションを確立します。 `runwayml/stable-diffusion-v1-5` と `stabilityai/stable-diffusion-2-1` の2つのモデルを利用できます。

この目的のために「顔推論APIを接続する」を選択します。

![action_list](https://cdn.illacloud.com/official-website/img/official-site/components/action_list.png)

このリソースの名前を入力し、Hugging Faceプラットフォームからトークンを入力します。

![hugging_config](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_config.png)

format@@0パネルにモデルIDとパラメータを入力してください。 選択したモデルをradioGroup1から取得しますので、モデルIDを`{{radioGroup1.value}}`と入力してください。 入力の場合は、入力フィールドから取得されるので、パラメータを`{{input1.value}}`と入力します。 以下の画像に示すように構成します。

![hugging_demo](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_demo.png)

「input」コンポーネントに「ファヴェーラ型のメカロボット」を入力し、アクションを実行しようとします。 実行結果は以下のとおりです。 左側のパネルから、`base64binary` と `dataURI` を含む、呼び出すことのできるデータを確認できます。

![hugging_output](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_output.png)

**ステップ 3: コンポーネントにデータを表示**

ステップ2から取得した画像を表示するには、イメージコンポーネントのイメージソースを`{{generateInput.fileData.dataURI}}`に変更します。 これにより、生成された画像を表示することができます。

![hugging_display](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_display.png)

**ステップ 4: コンポーネントでアクションを実行**

ボタンコンポーネントがクリックされたときにステップ2で作成されたアクションを実行するには、ボタンコンポーネントにイベントハンドラを追加します。

![hugging_event_config](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_event_config.png)

**ステップ 5: テスト**

前の4つのステップに沿って、追加のコンポーネントとデータソースを利用して他のタスクを完了し、より包括的なツールを構築できます。 たとえば、他のモデルを使用してプロンプトの生成や、localStorage やデータベースへのプロンプトの保存を支援することができます。 すべてのステップが実行された場合の完全な結果を見てみましょう。

![hugging_test](https://www.youtube.com/watch?v=SwAry_jIXns)

今、あなたはそれを遊ぶことができます! このAPIを通じてHugging faceによって提供される他の最先端モデルを試してみてください。 Stable diffusion anime modelsのダウンロード、アーティストスタイルのトレーニング、現実的な画像のサンプリング方法など、探求するべき多くがあります。 もっと多くのことができます！
