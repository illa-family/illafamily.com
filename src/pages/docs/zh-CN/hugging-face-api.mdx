---
title: Hugging Face API
metaTitle: Hugging Face API 集成doc | ILLA Cloud
desc: 学习如何在 ILLA 中使用 Hugging Face API
tagCategory: doc_menu_hugging_face_api_click
crowdinRepo: https://crowdin.com/multilingual/illacloud-website/213?languages=zhcn&filter=basic&value=0
categoryName: 🔨 数据集成
categoryPriority: 3
postPriority: 1
---

## <h2 hidden>Hugging Face API</h2>

Hugging Face is the Github of the machine learning community, with hundreds of thousands of pre-trained models and 10,000 datasets currently available. You can freely access models and datasets shared by other industry experts or host and deploy your models on Hugging Face.

Some examples of models available in the Hugging Face library include:

1.  BERT (Bidirectional Encoder Representations from Transformers): BERT is a transformer-based model developed by Google for various NLP tasks. It has achieved state-of-the-art results in language understanding and machine translation tasks.
2.  GPT (Generative Pre-training Transformer): GPT is another transformer-based model developed by OpenAI. It is primarily used for language generation tasks, such as translation and text summarization.
3.  RoBERTa (Robustly Optimized BERT): RoBERTa is an extension of the BERT model that was developed to improve BERT's performance on various NLP tasks.
4.  XLNet (eXtraordinary LanguageNet): XLNet is a transformer-based model developed by Google that is designed to improve the performance of transformer models on language understanding tasks.
5.  ALBERT (A Lite BERT): ALBERT is a version of the BERT model that was developed to be more efficient and faster to train while maintaining good performance on NLP tasks.

### What you can do with Hugging Face in ILLA Builder

In Hugging Face, over 130,000 machine-learning models are available through the public API, which you can use and test for free at <https://huggingface.co/models>. In addition, if you need a solution for production scenarios, you can use Hugging Face's Inference Endpoints, which can be deployed and accessed at <https://huggingface.co/docs/inference-endpoints/index>.

ILLA Builder provides dozens of commonly used front-end components, allowing you to build different front-end interfaces based on your specific needs quickly. At the same time, ILLA offers a connection to Hugging Face, allowing you to quickly connect to the API, send requests, and receive returned data. By connecting the API and front-end components, you can implement the requirement that users can enter content through the front end and submit it to the API. The API returns the generated content to be displayed on the front end.

### Configure Hugging Face API resource

| Properties | Required | Description                                                                              |
| ---------- | -------- | ---------------------------------------------------------------------------------------- |
| Name       | required | Define a resource name that will be used for display in ILLA                             |
| Token      | required | The user access or API token. You can get it in https://huggingface.co/settings/tokens.  |

### Configure Action

| Properties     | Required | Description                                                                                                                                                                                                                          |
| -------------- | -------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Model ID       | required | Search for models: https://huggingface.co/models                                                                                                                                                                                     |
| Parameter type | required | The parameter type of your endpoint. For example, if your endpoint needs an text input, choose fill in “inputs” parameter with text. If your endpoint needs an JSON input, choose fill in “inputs” parameter with JSON or key-value. |
| Parameter      | required | Enter your parameter. Use {{ componentName.value }} to use data of components.                                                                                                                                                       |

# How to use Hugging Face in ILLA Builder

## Usecase 1

### 步骤1：使用ILLA Builder上的组件构建UI

Here we will demonstrate how to build a simple text that input text prompt and a text question to output a text answer. 

You need two textarea components labeled as "Enter the original text" and "Enter the question here", and button component labeled as "Run", and a text area component labeled as "Anwer" for output text. The following image is an example as described above.

![hfapi](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi1.png)

### 步骤2：创建Hugging Face资源并配置Action

点击Action列表中的+New，然后选择Hugging Face Inference API。

![hfapi2](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi2.png)

填写表单以连接到您的Hugging Face：

名称：在ILLA中显示的名称

令牌：在你的Hugging Face [profile settings](https://huggingface.co/settings/tokens)

![hfapi3](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi3.png)

在配置Action之前，请确认Hugging Face中的模型信息：

在 [Hugging Face Model Page](https://huggingface.co/model) 中选择一个模型

我们使用 [deepset/roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2) 作为例子。 进入详情页面 > 点击Deploy按钮 > 点击Inference API

![hfapi4](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi4.png)

“inputs”后的参数是您应该在ILLA中填写的内容。 

![hfapi5](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi5.png)

在ILLA Builder中，我们应该填写模型ID和参数。 以上面的模型为例，“inputs”是一个键值对，因此我们可以使用key-value或JSON填充它。 

![hfapi6](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi6.png)

![hfapi7](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi7.png)

我们还支持文本输入和二进制输入，满足所有Hugging Face Inference API连接需求

### 步骤3：将Action连接到组件

为将用户的输入内容传递给API，您可以使用{{检索组件中输入的数据。 例如，输入2是输入问题的组件，输入1是输入上下文的组件。 我们可以用密钥填写`question`和`context`，然后填写`{{ input.value }}`值：

```jsx
{
"question": {{input2.value}},
"context": {{input1.value}}
}

```

在将Action的输出数据显示在前端组件中之前，我们应该确认不同模型的输出放置在哪个字段。仍以“deepset/roberta-base-squad2”为例，结果如下： 仍然以`deepset/roberta-base-squad2`为例，结果如下：

![hfapi8](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi8.png)

因此，我们可以使用“{{textQuestion.data [0] .answer}}”（“textQuestion”是操作的名称）获取API返回的答案。 

![hfapi9](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi9.png)

### 演示

![hfapi10](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi10.gif)

![hfapi11](https://cdn.illacloud.com/official-website/img/docs/connect/hfapi11.gif)

## Usecase 2

Here we will demonstrate how to use the Stable diffusion model thorugh the Hugging Face API in Illa Cloud.

**Step 1: Building a Front-end Interface**

We construct a front-end interface by utilizing a drag-and-drop approach to place essential components such as input fields, buttons, images, and more. After adjusting the styles of the components, we obtain the following complete webpage.

![hugging_layout](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_layout.png)

**Step 2: Creating Resources and Actions**

We establish resources and actions by utilizing the Hugging Face Inference API to connect to the Stable Diffusion model. Two models can be utilized: `runwayml/stable-diffusion-v1-5` and `stabilityai/stable-diffusion-2-1`.

Choose the "Hugging Face Inference API" for this purpose.

![action_list](https://cdn.illacloud.com/official-website/img/official-site/components/action_list.png)

Provide a name for this resource and enter your token from the Hugging Face platform.

![hugging_config](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_config.png)

In the Action configuration panel, please enter the Model ID and Parameter. We will retrieve the selected model from radioGroup1, so fill in the Model ID as  `{{radioGroup1.value}}` . For the input, since it is obtained from the input field, fill in the parameter as `{{input1.value}}`. The configuration should be as shown in the following image.

![hugging_demo](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_demo.png)

We attempt to input "A mecha robot in a favela in expressionist style" in the `input` component and run the Action. The resulting execution is as follows. From the left panel, you can observe the available data that can be called, including `base64binary` and `dataURI`.

![hugging_output](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_output.png)

**Step 3: Displaying Data on Components**

To display the image obtained from Step 2, we modify the Image source of the image component to `{{generateInput.fileData.dataURI}}`. This will enable us to show the generated image.

![hugging_display](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_display.png)

**Step 4: Running the Action with Components**

To run the action created in Step 2 when the button component is clicked, add an event handler to the button component.

![hugging_event_config](https://cdn.illacloud.com/official-website/img/official-site/components/hugging_event_config.png)

**Step 5: Testing**

Following the previous four steps, you can utilize additional components and data sources to complete other tasks and build a more comprehensive tool. For example, you can use other models to assist in generating prompts or store prompts in localStorage or a database. Let's take a look at the complete outcome when all the steps are implemented.

![hugging_test](https://www.youtube.com/watch?v=SwAry_jIXns)

Now you may play around with it! Try other cutting-edge models that is provided by Hugging face through this API. You can do much more!
